{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib as mpl\n",
    "import random\n",
    "#mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Lambda, Cropping2D\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from scipy import misc\n",
    "from scipy.ndimage import rotate\n",
    "from skimage import transform\n",
    "from skimage.transform import warp, SimilarityTransform, AffineTransform\n",
    "from skimage import exposure\n",
    "import os \n",
    "from os import listdir\n",
    "import glob\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from os import listdir\n",
    "import glob\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30D_9_1.png',\n",
       " '30D_9_2.png',\n",
       " '30D_9_3.png',\n",
       " '30D_9_4.png',\n",
       " '30D_9_5.png',\n",
       " '30D_9_6.png',\n",
       " '30D_9_7.png',\n",
       " '30D_9_8.png',\n",
       " '30D_9_9.png',\n",
       " '30D_9_10.png',\n",
       " '30D_9_11.png',\n",
       " '30D_9_12.png',\n",
       " '30D_9_13.png',\n",
       " '30D_9_14.png',\n",
       " '30D_9_15.png',\n",
       " '30D_9_16.png',\n",
       " '30D_9_17.png',\n",
       " '30D_9_18.png',\n",
       " '30D_9_19.png',\n",
       " '30D_9_20.png',\n",
       " '30D_9_21.png',\n",
       " '30D_9_22.png',\n",
       " '30D_9_23.png',\n",
       " '30D_9_24.png',\n",
       " '30D_9_25.png',\n",
       " '30D_9_26.png',\n",
       " '30D_9_27.png',\n",
       " '30D_9_28.png',\n",
       " '30D_9_29.png',\n",
       " '30D_9_30.png',\n",
       " '30D_9_31.png',\n",
       " '30D_9_32.png',\n",
       " '30D_9_33.png',\n",
       " '30D_9_34.png',\n",
       " '30D_9_35.png',\n",
       " '30D_9_36.png',\n",
       " '30D_9_37.png',\n",
       " '30D_9_38.png',\n",
       " '30D_9_39.png',\n",
       " '30D_9_40.png',\n",
       " '30D_9_41.png',\n",
       " '30D_9_42.png',\n",
       " '30D_9_43.png',\n",
       " '30D_9_44.png',\n",
       " '30D_9_45.png',\n",
       " '30D_9_46.png',\n",
       " '30D_9_47.png',\n",
       " '30D_9_48.png',\n",
       " '30D_9_49.png',\n",
       " '30D_9_50.png',\n",
       " '30D_9_51.png',\n",
       " '30D_9_52.png',\n",
       " '30D_9_53.png',\n",
       " '30D_9_54.png',\n",
       " '30D_9_55.png',\n",
       " '30D_9_56.png',\n",
       " '30D_9_57.png',\n",
       " '30D_9_58.png',\n",
       " '30D_9_59.png',\n",
       " '30D_9_60.png',\n",
       " '30D_9_61.png',\n",
       " '30D_9_62.png',\n",
       " '30D_9_63.png',\n",
       " '30D_9_64.png',\n",
       " '30D_9_65.png',\n",
       " '30D_9_66.png',\n",
       " '30D_9_67.png',\n",
       " '30D_9_68.png',\n",
       " '30D_9_69.png',\n",
       " '30D_9_70.png',\n",
       " '30D_9_71.png',\n",
       " '30D_9_72.png',\n",
       " '30D_9_73.png',\n",
       " '30D_9_74.png',\n",
       " '30D_9_75.png',\n",
       " '30D_9_76.png',\n",
       " '30D_9_77.png',\n",
       " '30D_9_78.png',\n",
       " '30D_9_79.png',\n",
       " '30D_9_80.png',\n",
       " '30D_9_81.png',\n",
       " '30D_9_82.png',\n",
       " '30D_9_83.png',\n",
       " '30D_9_84.png',\n",
       " '30D_9_85.png',\n",
       " '30D_9_86.png',\n",
       " '30D_9_87.png',\n",
       " '30D_9_88.png',\n",
       " '30D_9_89.png',\n",
       " '30D_9_90.png',\n",
       " '30D_9_91.png',\n",
       " '30D_9_92.png',\n",
       " '30D_9_93.png',\n",
       " '30D_9_94.png',\n",
       " '30D_9_95.png',\n",
       " '30D_9_96.png',\n",
       " '30D_9_97.png',\n",
       " '30D_9_98.png',\n",
       " '30D_9_99.png',\n",
       " '30D_9_100.png',\n",
       " '30D_9_101.png',\n",
       " '30D_9_102.png',\n",
       " '30D_9_103.png',\n",
       " '30D_9_104.png',\n",
       " '30D_9_105.png',\n",
       " '30D_9_106.png',\n",
       " '30D_9_107.png',\n",
       " '30D_9_108.png',\n",
       " '30D_9_109.png',\n",
       " '30D_9_110.png',\n",
       " '30D_9_111.png',\n",
       " '30D_9_112.png',\n",
       " '30D_9_113.png',\n",
       " '30D_9_114.png',\n",
       " '30D_9_115.png',\n",
       " '30D_9_116.png',\n",
       " '30D_9_117.png',\n",
       " '30D_9_118.png',\n",
       " '30D_9_119.png',\n",
       " '30D_9_120.png',\n",
       " '30D_9_121.png',\n",
       " '30D_9_122.png',\n",
       " '30D_9_123.png',\n",
       " '30D_9_124.png',\n",
       " '30D_9_125.png',\n",
       " '30D_9_126.png',\n",
       " '30D_9_127.png',\n",
       " '30D_9_128.png',\n",
       " '30D_9_129.png',\n",
       " '30D_9_130.png',\n",
       " '30D_9_131.png',\n",
       " '30D_9_132.png',\n",
       " '30D_9_133.png',\n",
       " '30D_9_134.png',\n",
       " '30D_9_135.png',\n",
       " '30D_9_136.png',\n",
       " '30D_9_137.png',\n",
       " '30D_9_138.png',\n",
       " '30D_9_139.png',\n",
       " '30D_9_140.png',\n",
       " '30D_9_141.png',\n",
       " '30D_9_142.png',\n",
       " '30D_9_143.png',\n",
       " '30D_9_144.png',\n",
       " '30D_9_145.png',\n",
       " '30D_9_146.png',\n",
       " '30D_9_147.png',\n",
       " '30D_9_148.png',\n",
       " '30D_9_149.png',\n",
       " '30D_9_150.png',\n",
       " '30D_9_151.png',\n",
       " '30D_9_152.png',\n",
       " '30D_9_153.png',\n",
       " '30D_9_154.png',\n",
       " '30D_9_155.png',\n",
       " '30D_9_156.png',\n",
       " '30D_9_157.png',\n",
       " '30D_9_158.png',\n",
       " '30D_9_159.png',\n",
       " '30D_9_160.png',\n",
       " '30D_9_161.png',\n",
       " '30D_9_162.png',\n",
       " '30D_9_163.png',\n",
       " '30D_9_164.png',\n",
       " '30D_9_165.png',\n",
       " '30D_9_166.png',\n",
       " '30D_9_167.png',\n",
       " '30D_9_168.png',\n",
       " '30D_9_169.png',\n",
       " '30D_9_170.png',\n",
       " '30D_9_171.png',\n",
       " '30D_9_172.png',\n",
       " '30D_9_173.png',\n",
       " '30D_9_174.png',\n",
       " '30D_9_175.png',\n",
       " '30D_9_176.png',\n",
       " '30D_9_177.png',\n",
       " '30D_9_178.png',\n",
       " '30D_9_179.png',\n",
       " '30D_9_180.png',\n",
       " '30D_9_181.png',\n",
       " '30D_9_182.png',\n",
       " '30D_9_183.png',\n",
       " '30D_9_184.png',\n",
       " '30D_9_185.png',\n",
       " '30D_9_186.png',\n",
       " '30D_9_187.png',\n",
       " '30D_9_188.png',\n",
       " '30D_9_189.png',\n",
       " '30D_9_190.png',\n",
       " '30D_9_191.png',\n",
       " '30D_9_192.png',\n",
       " '30D_9_193.png',\n",
       " '30D_9_194.png',\n",
       " '30D_9_195.png',\n",
       " '30D_9_196.png',\n",
       " '30D_9_197.png',\n",
       " '30D_9_198.png',\n",
       " '30D_9_199.png',\n",
       " '30D_9_200.png',\n",
       " '30D_9_201.png',\n",
       " '30D_9_202.png',\n",
       " '30D_9_203.png',\n",
       " '30D_9_204.png',\n",
       " '30D_9_205.png',\n",
       " '30D_9_206.png',\n",
       " '30D_9_207.png',\n",
       " '30D_9_208.png',\n",
       " '30D_9_209.png',\n",
       " '30D_9_210.png',\n",
       " '30D_9_211.png',\n",
       " '30D_9_212.png',\n",
       " '30D_9_213.png',\n",
       " '30D_9_214.png',\n",
       " '30D_9_215.png',\n",
       " '30D_9_216.png',\n",
       " '30D_9_217.png',\n",
       " '30D_9_218.png',\n",
       " '30D_9_219.png',\n",
       " '30D_9_220.png',\n",
       " '30D_9_221.png',\n",
       " '30D_9_222.png',\n",
       " '30D_9_223.png',\n",
       " '30D_9_224.png',\n",
       " '30D_9_225.png',\n",
       " '30D_9_226.png',\n",
       " '30D_9_227.png',\n",
       " '30D_9_228.png',\n",
       " '30D_9_229.png',\n",
       " '30D_9_230.png',\n",
       " '30D_9_231.png',\n",
       " '30D_9_232.png',\n",
       " '30D_9_233.png',\n",
       " '30D_9_234.png',\n",
       " '30D_9_235.png',\n",
       " '30D_9_236.png',\n",
       " '30D_9_237.png',\n",
       " '30D_9_238.png',\n",
       " '30D_9_239.png',\n",
       " '30D_9_240.png',\n",
       " '30D_9_241.png',\n",
       " '30D_9_242.png',\n",
       " '30D_9_243.png',\n",
       " '30D_9_244.png',\n",
       " '30D_9_245.png',\n",
       " '30D_9_246.png',\n",
       " '30D_9_247.png',\n",
       " '30D_9_248.png',\n",
       " '30D_9_249.png',\n",
       " '30D_9_250.png',\n",
       " '30D_9_251.png',\n",
       " '30D_9_252.png',\n",
       " '30D_9_253.png',\n",
       " '30D_9_254.png',\n",
       " '30D_9_255.png',\n",
       " '30D_9_256.png',\n",
       " '30D_9_257.png',\n",
       " '30D_9_258.png',\n",
       " '30D_9_259.png',\n",
       " '30D_9_260.png',\n",
       " '30D_9_261.png',\n",
       " '30D_9_262.png',\n",
       " '30D_9_263.png',\n",
       " '30D_9_264.png',\n",
       " '30D_9_265.png',\n",
       " '30D_9_266.png',\n",
       " '30D_9_267.png',\n",
       " '30D_9_268.png',\n",
       " '30D_9_269.png',\n",
       " '30D_9_270.png',\n",
       " '30D_9_271.png',\n",
       " '30D_9_272.png',\n",
       " '30D_9_273.png',\n",
       " '30D_9_274.png',\n",
       " '30D_9_275.png',\n",
       " '30D_9_276.png',\n",
       " '30D_9_277.png',\n",
       " '30D_9_278.png',\n",
       " '30D_9_279.png',\n",
       " '30D_9_280.png',\n",
       " '30D_9_281.png',\n",
       " '30D_9_282.png',\n",
       " '30D_9_283.png',\n",
       " '30D_9_284.png',\n",
       " '30D_9_285.png',\n",
       " '30D_9_286.png',\n",
       " '30D_9_287.png',\n",
       " '30D_9_288.png',\n",
       " '30D_9_289.png',\n",
       " '30D_9_290.png',\n",
       " '30D_9_291.png',\n",
       " '30D_9_292.png',\n",
       " '30D_9_293.png',\n",
       " '30D_9_294.png',\n",
       " '30D_9_295.png',\n",
       " '30D_9_296.png',\n",
       " '30D_9_297.png',\n",
       " '30D_9_298.png',\n",
       " '30D_9_299.png',\n",
       " '30D_9_300.png',\n",
       " '30D_9_301.png',\n",
       " '30D_9_302.png',\n",
       " '30D_9_303.png',\n",
       " '30D_9_304.png',\n",
       " '30D_9_305.png',\n",
       " '30D_9_306.png',\n",
       " '30D_9_307.png',\n",
       " '30D_9_308.png',\n",
       " '30D_9_309.png',\n",
       " '30D_9_310.png',\n",
       " '30D_9_311.png',\n",
       " '30D_9_312.png',\n",
       " '30D_9_313.png',\n",
       " '30D_9_314.png',\n",
       " '30D_9_315.png',\n",
       " '30D_9_316.png',\n",
       " '30D_9_317.png',\n",
       " '30D_9_318.png',\n",
       " '30D_9_319.png',\n",
       " '30D_9_320.png',\n",
       " '30D_9_321.png',\n",
       " '30D_9_322.png',\n",
       " '30D_9_323.png',\n",
       " '30D_9_324.png',\n",
       " '30D_9_325.png',\n",
       " '30D_9_326.png',\n",
       " '30D_9_327.png',\n",
       " '30D_9_328.png',\n",
       " '30D_9_329.png',\n",
       " '30D_9_330.png',\n",
       " '30D_9_331.png',\n",
       " '30D_9_332.png',\n",
       " '30D_9_333.png',\n",
       " '30D_9_334.png',\n",
       " '30D_9_335.png',\n",
       " '30D_9_336.png',\n",
       " '30D_9_337.png',\n",
       " '30D_9_338.png',\n",
       " '30D_9_339.png',\n",
       " '30D_9_340.png',\n",
       " '30D_9_341.png',\n",
       " '30D_9_342.png',\n",
       " '30D_9_343.png',\n",
       " '30D_9_344.png',\n",
       " '30D_9_345.png',\n",
       " '30D_9_346.png',\n",
       " '30D_9_347.png',\n",
       " '30D_9_348.png',\n",
       " '30D_9_349.png',\n",
       " '30D_9_350.png',\n",
       " '30D_9_351.png',\n",
       " '30D_9_352.png',\n",
       " '30D_9_353.png',\n",
       " '30D_9_354.png',\n",
       " '30D_9_355.png',\n",
       " '30D_9_356.png',\n",
       " '30D_9_357.png',\n",
       " '30D_9_358.png',\n",
       " '30D_9_359.png',\n",
       " '30D_9_360.png',\n",
       " '30D_9_361.png',\n",
       " '30D_9_362.png',\n",
       " '30D_9_363.png',\n",
       " '30D_9_364.png',\n",
       " '30D_9_365.png',\n",
       " '30D_9_366.png',\n",
       " '30D_9_367.png',\n",
       " '30D_9_368.png',\n",
       " '30D_9_369.png',\n",
       " '30D_9_370.png',\n",
       " '30D_9_371.png',\n",
       " '30D_9_372.png',\n",
       " '30D_9_373.png',\n",
       " '30D_9_374.png',\n",
       " '30D_9_375.png',\n",
       " '30D_9_376.png',\n",
       " '30D_9_377.png',\n",
       " '30D_9_378.png',\n",
       " '30D_9_379.png',\n",
       " '30D_9_380.png',\n",
       " '30D_9_381.png',\n",
       " '30D_9_382.png',\n",
       " '30D_9_383.png',\n",
       " '30D_9_384.png',\n",
       " '30D_9_385.png',\n",
       " '30D_9_386.png',\n",
       " '30D_9_387.png',\n",
       " '30D_9_388.png',\n",
       " '30D_9_389.png',\n",
       " '30D_9_390.png',\n",
       " '30D_9_391.png',\n",
       " '30D_9_392.png',\n",
       " '30D_9_393.png',\n",
       " '30D_9_394.png',\n",
       " '30D_9_395.png',\n",
       " '30D_9_396.png',\n",
       " '30D_9_397.png',\n",
       " '30D_9_398.png',\n",
       " '30D_9_399.png',\n",
       " '30D_9_400.png',\n",
       " '30D_9_401.png',\n",
       " '30D_9_402.png',\n",
       " '30D_9_403.png',\n",
       " '30D_9_404.png',\n",
       " '30D_9_405.png',\n",
       " '30D_9_406.png',\n",
       " '30D_9_407.png',\n",
       " '30D_9_408.png',\n",
       " '30D_9_409.png',\n",
       " '30D_9_410.png',\n",
       " '30D_9_411.png',\n",
       " '30D_9_412.png',\n",
       " '30D_9_413.png',\n",
       " '30D_9_414.png',\n",
       " '30D_9_415.png',\n",
       " '30D_9_416.png',\n",
       " '30D_9_417.png',\n",
       " '30D_9_418.png',\n",
       " '30D_9_419.png',\n",
       " '30D_9_420.png',\n",
       " '30D_9_421.png',\n",
       " '30D_9_422.png',\n",
       " '30D_9_423.png',\n",
       " '30D_9_424.png',\n",
       " '30D_9_425.png',\n",
       " '30D_9_426.png',\n",
       " '30D_9_427.png',\n",
       " '30D_9_428.png',\n",
       " '30D_9_429.png',\n",
       " '30D_9_430.png',\n",
       " '30D_9_431.png',\n",
       " '30D_9_432.png',\n",
       " '30D_9_433.png',\n",
       " '30D_9_434.png',\n",
       " '30D_9_435.png',\n",
       " '30D_9_436.png',\n",
       " '30D_9_437.png',\n",
       " '30D_9_438.png',\n",
       " '30D_9_439.png',\n",
       " '30D_9_440.png',\n",
       " '30D_9_441.png',\n",
       " '30D_9_442.png',\n",
       " '30D_9_443.png',\n",
       " '30D_9_444.png',\n",
       " '30D_9_445.png',\n",
       " '30D_9_446.png',\n",
       " '30D_9_447.png',\n",
       " '30D_9_448.png',\n",
       " '30D_9_449.png',\n",
       " '30D_9_450.png',\n",
       " '30D_9_451.png',\n",
       " '30D_9_452.png',\n",
       " '30D_9_453.png',\n",
       " '30D_9_454.png',\n",
       " '30D_9_455.png',\n",
       " '30D_9_456.png',\n",
       " '30D_9_457.png',\n",
       " '30D_9_458.png',\n",
       " '30D_9_459.png',\n",
       " '30D_9_460.png',\n",
       " '30D_9_461.png',\n",
       " '30D_9_462.png',\n",
       " '30D_9_463.png',\n",
       " '30D_9_464.png',\n",
       " '30D_9_465.png',\n",
       " '30D_9_466.png',\n",
       " '30D_9_467.png',\n",
       " '30D_9_468.png',\n",
       " '30D_9_469.png',\n",
       " '30D_9_470.png',\n",
       " '30D_9_471.png',\n",
       " '30D_9_472.png',\n",
       " '30D_9_473.png',\n",
       " '30D_9_474.png',\n",
       " '30D_9_475.png',\n",
       " '30D_9_476.png',\n",
       " '30D_9_477.png',\n",
       " '30D_9_478.png',\n",
       " '30D_9_479.png',\n",
       " '30D_9_480.png',\n",
       " '30D_9_481.png',\n",
       " '30D_9_482.png',\n",
       " '30D_9_483.png',\n",
       " '30D_9_484.png',\n",
       " '30D_9_485.png',\n",
       " '30D_9_486.png',\n",
       " '30D_9_487.png',\n",
       " '30D_9_488.png',\n",
       " '30D_9_489.png',\n",
       " '30D_9_490.png',\n",
       " '30D_9_491.png',\n",
       " '30D_9_492.png',\n",
       " '30D_9_493.png',\n",
       " '30D_9_494.png',\n",
       " '30D_9_495.png',\n",
       " '30D_9_496.png',\n",
       " '30D_9_497.png',\n",
       " '30D_9_498.png',\n",
       " '30D_9_499.png',\n",
       " '30D_9_500.png',\n",
       " '30D_9_501.png',\n",
       " '30D_9_502.png',\n",
       " '30D_9_503.png',\n",
       " '30D_9_504.png',\n",
       " '30D_9_505.png',\n",
       " '30D_9_506.png',\n",
       " '30D_9_507.png',\n",
       " '30D_9_508.png',\n",
       " '30D_9_509.png',\n",
       " '30D_9_510.png',\n",
       " '30D_9_511.png',\n",
       " '30D_9_512.png',\n",
       " '30D_9_513.png',\n",
       " '30D_9_514.png',\n",
       " '30D_9_515.png',\n",
       " '30D_9_516.png',\n",
       " '30D_9_517.png',\n",
       " '30D_9_518.png',\n",
       " '30D_9_519.png',\n",
       " '30D_9_520.png',\n",
       " '30D_9_521.png',\n",
       " '30D_9_522.png',\n",
       " '30D_9_523.png',\n",
       " '30D_9_524.png',\n",
       " '30D_9_525.png',\n",
       " '30D_9_526.png',\n",
       " '30D_9_527.png',\n",
       " '30D_9_528.png',\n",
       " '30D_9_529.png',\n",
       " '30D_9_530.png',\n",
       " '30D_9_531.png',\n",
       " '30D_9_532.png',\n",
       " '30D_9_533.png',\n",
       " '30D_9_534.png',\n",
       " '30D_9_535.png',\n",
       " '30D_9_536.png',\n",
       " '30D_9_537.png',\n",
       " '30D_9_538.png',\n",
       " '30D_9_539.png',\n",
       " '30D_9_540.png',\n",
       " '30D_9_541.png',\n",
       " '30D_9_542.png',\n",
       " '30D_9_543.png',\n",
       " '30D_9_544.png',\n",
       " '30D_9_545.png',\n",
       " '30D_9_546.png',\n",
       " '30D_9_547.png',\n",
       " '30D_9_548.png',\n",
       " '30D_9_549.png',\n",
       " '30D_9_550.png',\n",
       " '30D_9_551.png',\n",
       " '30D_9_552.png',\n",
       " '30D_9_553.png',\n",
       " '30D_9_554.png',\n",
       " '30D_9_555.png',\n",
       " '30D_9_556.png',\n",
       " '30D_9_557.png',\n",
       " '30D_9_558.png',\n",
       " '30D_9_559.png',\n",
       " '30D_9_560.png',\n",
       " '30D_9_561.png',\n",
       " '30D_9_562.png',\n",
       " '30D_9_563.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"30D_1/New directory/Img/\")\n",
    "filenames = [img for img in glob.glob(\"*.png\")]\n",
    "import re\n",
    "tokenize = re.compile(r'(\\d+)|(\\D+)').findall\n",
    "def natural_sortkey(string):          \n",
    "    return tuple(int(num) if num else alpha for num, alpha in tokenize(string))\n",
    "\n",
    "files = sorted(filenames, key=natural_sortkey)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../30D_9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(len(files)):\n",
    "    images.append(mpimg.imread(files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.000377\n",
       "1      0.000592\n",
       "2      0.000774\n",
       "3      0.000891\n",
       "4      0.001091\n",
       "         ...   \n",
       "558    0.120700\n",
       "559    0.120900\n",
       "560    0.121200\n",
       "561    0.121500\n",
       "562    0.121700\n",
       "Name: strain, Length: 563, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"strain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(images)\n",
    "\n",
    "y = np.array(labels[\"stress\"]).max()\n",
    "y_train = np.array(labels[\"stress\"])/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35192937, 0.55140615, 0.71877044, 0.82603009, 1.        ,\n",
       "       0.81425768, 0.65533028, 0.51098757, 0.42910399, 0.37311969,\n",
       "       0.39489863, 0.41066056, 0.42393721, 0.42740353, 0.44100719,\n",
       "       0.47730543, 0.46664487, 0.44571615, 0.43597122, 0.43989536,\n",
       "       0.4559843 , 0.45448005, 0.4824722 , 0.47848267, 0.48423806,\n",
       "       0.48940484, 0.49862655, 0.50124264, 0.49372139, 0.49895356,\n",
       "       0.49483322, 0.49529104, 0.47580118, 0.47272727, 0.47037279,\n",
       "       0.45676913, 0.44290386, 0.43283192, 0.45271419, 0.42537606,\n",
       "       0.39947678, 0.39156311, 0.38966645, 0.39306736, 0.39646828,\n",
       "       0.39568345, 0.39587966, 0.41661216, 0.41909745, 0.42661871,\n",
       "       0.42812296, 0.42583388, 0.43544801, 0.42465664, 0.44480052,\n",
       "       0.44336167, 0.43485939, 0.43649444, 0.43950294, 0.44741661,\n",
       "       0.44362328, 0.44460432, 0.4500327 , 0.45369523, 0.44480052,\n",
       "       0.44290386, 0.44767822, 0.44316547, 0.43858731, 0.4412034 ,\n",
       "       0.44604317, 0.44983649, 0.4440157 , 0.45689993, 0.45179856,\n",
       "       0.44512753, 0.4646174 , 0.45330281, 0.4469588 , 0.458862  ,\n",
       "       0.46023545, 0.45860039, 0.46043165, 0.45160235, 0.45055592,\n",
       "       0.46514061, 0.44551995, 0.44885546, 0.45820798, 0.44486593,\n",
       "       0.45075213, 0.45192937, 0.44316547, 0.44937868, 0.44650098,\n",
       "       0.44224984, 0.4470242 , 0.44911707, 0.447155  , 0.43924133,\n",
       "       0.44224984, 0.45277959, 0.43662525, 0.42956181, 0.44506213,\n",
       "       0.43328973, 0.42858077, 0.4382603 , 0.44807063, 0.43891432,\n",
       "       0.43132767, 0.43917593, 0.45173316, 0.44336167, 0.4412034 ,\n",
       "       0.43727927, 0.44486593, 0.4442119 , 0.43485939, 0.43636364,\n",
       "       0.43917593, 0.4470242 , 0.44277305, 0.43015043, 0.43289732,\n",
       "       0.44486593, 0.447155  , 0.43217789, 0.4204709 , 0.43839111,\n",
       "       0.43283192, 0.43015043, 0.42099411, 0.44041857, 0.43446697,\n",
       "       0.42629169, 0.43747547, 0.43760628, 0.44264225, 0.45853499,\n",
       "       0.45258339, 0.44820144, 0.45408764, 0.46899935, 0.45604971,\n",
       "       0.44905167, 0.46527142, 0.45820798, 0.45101373, 0.44453891,\n",
       "       0.46115108, 0.45101373, 0.44512753, 0.44663179, 0.45179856,\n",
       "       0.44630477, 0.43198169, 0.44558535, 0.44440811, 0.45376063,\n",
       "       0.44185742, 0.43355134, 0.43930674, 0.44185742, 0.42289078,\n",
       "       0.42557227, 0.44512753, 0.43773708, 0.42531066, 0.44251145,\n",
       "       0.43328973, 0.42831916, 0.43878352, 0.43610203, 0.44264225,\n",
       "       0.43799869, 0.44316547, 0.45323741, 0.44388489, 0.45199477,\n",
       "       0.46082407, 0.44852845, 0.46082407, 0.46069326, 0.45081753,\n",
       "       0.45317201, 0.45179856, 0.44166122, 0.45062132, 0.44780903,\n",
       "       0.44192283, 0.45421844, 0.45742315, 0.4324395 , 0.4469588 ,\n",
       "       0.45807717, 0.44551995, 0.44591236, 0.46128188, 0.44591236,\n",
       "       0.4559189 , 0.45441465, 0.44460432, 0.45153695, 0.44068018,\n",
       "       0.42818836, 0.44336167, 0.4440157 , 0.44342708, 0.44054938,\n",
       "       0.44257685, 0.44722041, 0.43413996, 0.44041857, 0.44885546,\n",
       "       0.43727927, 0.43917593, 0.4529104 , 0.43760628, 0.4324395 ,\n",
       "       0.44669719, 0.43839111, 0.42321779, 0.44179202, 0.44395029,\n",
       "       0.43276651, 0.45016351, 0.46945716, 0.45657292, 0.45382603,\n",
       "       0.46860693, 0.44813604, 0.45801177, 0.45696534, 0.44538914,\n",
       "       0.45428385, 0.45519948, 0.44192283, 0.44172662, 0.44937868,\n",
       "       0.44499673, 0.42818836, 0.4441465 , 0.45604971, 0.44800523,\n",
       "       0.4470242 , 0.44741661, 0.45349902, 0.43505559, 0.43440157,\n",
       "       0.45356442, 0.44153041, 0.43067364, 0.44780903, 0.441138  ,\n",
       "       0.43047744, 0.4383257 , 0.44748201, 0.44388489, 0.43015043,\n",
       "       0.44937868, 0.44584696, 0.44885546, 0.44048398, 0.44826684,\n",
       "       0.4499673 , 0.45676913, 0.43642904, 0.43695226, 0.45245258,\n",
       "       0.44159581, 0.43335513, 0.43996076, 0.45277959, 0.44264225,\n",
       "       0.43034663, 0.44852845, 0.44650098, 0.4410726 , 0.42688031,\n",
       "       0.44604317, 0.44453891, 0.43250491, 0.44650098, 0.44525834,\n",
       "       0.45206017, 0.44584696, 0.45206017, 0.47004578, 0.45029431,\n",
       "       0.45062132, 0.46383257, 0.44290386, 0.43682145, 0.43152387,\n",
       "       0.45925441, 0.45755396, 0.45860039, 0.45971223, 0.46285154,\n",
       "       0.46252453, 0.44610857, 0.45761936, 0.45931982, 0.4559189 ,\n",
       "       0.45624591, 0.45722695, 0.46749509, 0.4735121 , 0.46023545,\n",
       "       0.46075867, 0.47305428, 0.47508175, 0.45480706, 0.42040549,\n",
       "       0.42491825, 0.42380641, 0.44362328, 0.43976455, 0.44970569,\n",
       "       0.45389143, 0.45081753, 0.45160235, 0.45343362, 0.46834532,\n",
       "       0.458862  , 0.45029431, 0.45310661, 0.46455199, 0.46023545,\n",
       "       0.45317201, 0.46913015, 0.46239372, 0.46932636, 0.4587312 ,\n",
       "       0.47338129, 0.4648136 , 0.45140615, 0.43335513, 0.42262917,\n",
       "       0.42432963, 0.44381949, 0.42086331, 0.43492479, 0.4293002 ,\n",
       "       0.43008502, 0.42524526, 0.44551995, 0.42674951, 0.44466972,\n",
       "       0.42413342, 0.41935906, 0.43564421, 0.42583388, 0.42432963,\n",
       "       0.42733813, 0.41550033, 0.41628515, 0.41733159, 0.41661216,\n",
       "       0.43865271, 0.44565075, 0.42812296, 0.44826684, 0.43708306,\n",
       "       0.45147155, 0.43178548, 0.41589274, 0.41098757, 0.43610203,\n",
       "       0.44447351, 0.45199477, 0.42517986, 0.44813604, 0.44224984,\n",
       "       0.44656638, 0.43433617, 0.44578156, 0.45173316, 0.45395683,\n",
       "       0.4469588 , 0.46219751, 0.45062132, 0.45160235, 0.44362328,\n",
       "       0.44761282, 0.4499673 , 0.45918901, 0.45454545, 0.45493787,\n",
       "       0.45683453, 0.45487247, 0.45225638, 0.45945062, 0.45925441,\n",
       "       0.4558535 , 0.4499019 , 0.45206017, 0.43459778, 0.44499673,\n",
       "       0.43741007, 0.43884892, 0.44767822, 0.45166776, 0.46056246,\n",
       "       0.47298888, 0.46232832, 0.47024199, 0.47390451, 0.46749509,\n",
       "       0.44538914, 0.44310007, 0.46553303, 0.4440811 , 0.46971877,\n",
       "       0.47181164, 0.44499673, 0.45068672, 0.45493787, 0.46801831,\n",
       "       0.46736429, 0.45107914, 0.47200785, 0.44950948, 0.45101373,\n",
       "       0.42498365, 0.46213211, 0.43139307, 0.43328973, 0.46082407,\n",
       "       0.44643558, 0.45761936, 0.44205363, 0.47436233, 0.45755396,\n",
       "       0.48083715, 0.47979071, 0.43021583, 0.40640942, 0.45461086,\n",
       "       0.45088293, 0.46814912, 0.46239372, 0.47442773, 0.46651406,\n",
       "       0.4264225 , 0.45604971, 0.45559189, 0.46533682, 0.4647482 ,\n",
       "       0.48554611, 0.45860039, 0.48711576, 0.46945716, 0.47292348,\n",
       "       0.45761936, 0.44440811, 0.40503597, 0.43374755, 0.42524526,\n",
       "       0.42105952, 0.45232178, 0.44440811, 0.45683453, 0.441138  ,\n",
       "       0.45349902, 0.43472858, 0.45493787, 0.46886854, 0.46448659,\n",
       "       0.44224984, 0.45441465, 0.44538914, 0.45206017, 0.43047744,\n",
       "       0.43636364, 0.43976455, 0.45526488, 0.46232832, 0.4736429 ,\n",
       "       0.46069326, 0.47776324, 0.45382603, 0.48776978, 0.47684761,\n",
       "       0.48463048, 0.47475474, 0.46703728, 0.41981687, 0.46586004,\n",
       "       0.46723349, 0.41903205, 0.48495749, 0.48181818, 0.56854153,\n",
       "       0.63714846, 0.6147809 , 0.55192937, 0.49646828, 0.49914977,\n",
       "       0.51491171, 0.46272073, 0.48070634, 0.45336821, 0.48077175,\n",
       "       0.5057554 , 0.5381295 , 0.47567037, 0.4057554 , 0.45166776,\n",
       "       0.44571615, 0.48064094, 0.458862  , 0.4500981 , 0.45801177,\n",
       "       0.4941138 , 0.49973839, 0.49483322, 0.48593852, 0.46801831,\n",
       "       0.45768476, 0.46605625, 0.46886854, 0.45519948, 0.44087639,\n",
       "       0.46736429, 0.45094833, 0.47259647, 0.43741007, 0.47468934,\n",
       "       0.44748201, 0.47619359, 0.46651406, 0.4792675 , 0.48803139,\n",
       "       0.47017659, 0.45343362, 0.42151733, 0.36154349, 0.32164814,\n",
       "       0.33322433, 0.31988228, 0.30313931, 0.37187704, 0.38763898,\n",
       "       0.35565729, 0.4293002 , 0.39542184, 0.33858731, 0.4118378 ,\n",
       "       0.37168084, 0.4057554 , 0.4028123 , 0.35683453, 0.28927404,\n",
       "       0.31916285, 0.31857423, 0.27383911, 0.31497711, 0.29535644,\n",
       "       0.33701766, 0.38580772, 0.34767822])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#The architecture is similar to NVIDIA architecture. It starts with convolutional layers that have \n",
    "#24, 36 and 48 , 5x5 filters respectively in the first 3 layers and a stride of 2 in both the directions.\n",
    "#These layers are followed by two convolutional layers each having 64 3x3 filters with strides of 1\n",
    "#in both the directions. Exponential Linear Unit activation function is used in all the five convolutional\n",
    "#layers. A maxpooling layer follows. The layer is flattened and fed into four fully connected layers with\n",
    "#first two having ELU activation. Dropout is applied in each layer after the first one with a probability of\n",
    "#retaining the weights equal to 0.5. It was also realized that maxpooling layers take a long time\n",
    "model.add(Convolution2D(24,(2,2), padding = 'valid', strides = (2,2), activation='elu'))\n",
    "model.add(Convolution2D(36,(2,2), padding = 'valid', strides = (2,2), activation='elu'))\n",
    "model.add(Convolution2D(48,(3,3), padding = 'valid', strides = (2,2), activation='elu'))\n",
    "model.add(Convolution2D(64,(3,3), padding = 'valid', strides = (1,1), activation='elu'))\n",
    "model.add(Convolution2D(64,(3,3), padding = 'valid', strides = (1,1), activation='elu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation = 'elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 422 samples, validate on 141 samples\n",
      "Epoch 1/30\n",
      "422/422 [==============================] - 21s 50ms/step - loss: 0.7932 - val_loss: 0.0580\n",
      "Epoch 2/30\n",
      "422/422 [==============================] - 19s 45ms/step - loss: 0.5329 - val_loss: 0.0393\n",
      "Epoch 3/30\n",
      "422/422 [==============================] - 19s 44ms/step - loss: 0.4931 - val_loss: 0.0171\n",
      "Epoch 4/30\n",
      "422/422 [==============================] - 18s 43ms/step - loss: 0.4400 - val_loss: 0.0158\n",
      "Epoch 5/30\n",
      "422/422 [==============================] - 18s 44ms/step - loss: 0.3746 - val_loss: 0.0128\n",
      "Epoch 6/30\n",
      "422/422 [==============================] - 18s 43ms/step - loss: 0.3400 - val_loss: 0.0077\n",
      "Epoch 7/30\n",
      "422/422 [==============================] - 18s 44ms/step - loss: 0.3193 - val_loss: 0.0084\n",
      "Epoch 8/30\n",
      "422/422 [==============================] - 18s 43ms/step - loss: 0.2779 - val_loss: 0.0099\n",
      "Epoch 9/30\n",
      "422/422 [==============================] - 18s 43ms/step - loss: 0.2996 - val_loss: 0.0082\n",
      "Epoch 10/30\n",
      "422/422 [==============================] - 18s 43ms/step - loss: 0.2633 - val_loss: 0.0090\n",
      "Epoch 11/30\n",
      "422/422 [==============================] - 18s 43ms/step - loss: 0.2452 - val_loss: 0.0109\n",
      "Epoch 12/30\n",
      "422/422 [==============================] - 19s 45ms/step - loss: 0.2083 - val_loss: 0.0070\n",
      "Epoch 13/30\n",
      "422/422 [==============================] - 21s 50ms/step - loss: 0.2029 - val_loss: 0.0105\n",
      "Epoch 14/30\n",
      "422/422 [==============================] - 20s 48ms/step - loss: 0.2246 - val_loss: 0.0091\n",
      "Epoch 15/30\n",
      "422/422 [==============================] - 19s 44ms/step - loss: 0.1930 - val_loss: 0.0081\n",
      "Epoch 16/30\n",
      "422/422 [==============================] - 14s 33ms/step - loss: 0.1705 - val_loss: 0.0068\n",
      "Epoch 17/30\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.1832 - val_loss: 0.0075\n",
      "Epoch 18/30\n",
      "422/422 [==============================] - 13s 30ms/step - loss: 0.1705 - val_loss: 0.0084\n",
      "Epoch 19/30\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.1711 - val_loss: 0.0084\n",
      "Epoch 20/30\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.1398 - val_loss: 0.0109\n",
      "Epoch 21/30\n",
      "422/422 [==============================] - 14s 33ms/step - loss: 0.1517 - val_loss: 0.0082\n",
      "Epoch 22/30\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.1433 - val_loss: 0.0089\n",
      "Epoch 23/30\n",
      "422/422 [==============================] - 13s 32ms/step - loss: 0.1327 - val_loss: 0.0093\n",
      "Epoch 24/30\n",
      "422/422 [==============================] - 13s 32ms/step - loss: 0.1301 - val_loss: 0.0093\n",
      "Epoch 25/30\n",
      "422/422 [==============================] - 13s 30ms/step - loss: 0.1280 - val_loss: 0.0083\n",
      "Epoch 26/30\n",
      "422/422 [==============================] - 12s 29ms/step - loss: 0.1256 - val_loss: 0.0092\n",
      "Epoch 27/30\n",
      "422/422 [==============================] - 11s 27ms/step - loss: 0.1141 - val_loss: 0.0076\n",
      "Epoch 28/30\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1164 - val_loss: 0.0074\n",
      "Epoch 29/30\n",
      "422/422 [==============================] - 7s 16ms/step - loss: 0.0961 - val_loss: 0.0093\n",
      "Epoch 30/30\n",
      "422/422 [==============================] - 7s 18ms/step - loss: 0.1102 - val_loss: 0.0090\n"
     ]
    }
   ],
   "source": [
    "#sgd = tf.keras.optimizers.SGD()\n",
    "sgd = optimizers.SGD(lr=0.00001)\n",
    "#model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "model.compile(loss = 'mse', optimizer = sgd)    #mse is used here instead of a cross entropy function because it is a regression and not a classification\n",
    "hist = model.fit(X_train, y_train, batch_size = 20, validation_split = 0.25, shuffle = True, epochs = 30)\n",
    "\n",
    "\n",
    "#model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(hist.history)\n",
    "train_loss = hist.history['loss']\n",
    "val_loss   = hist.history['val_loss']\n",
    "\n",
    "predicted_strain = []\n",
    "l = []\n",
    "for i in range(len(files)):\n",
    "    image = images[i]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    k = (model.predict(image))*y\n",
    "    l.append(k[0][0])\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "plt.xlabel(\"Strain\",fontsize = 14)\n",
    "plt.ylabel(\"Stress (x10 MPa)\",fontsize = 14)\n",
    "\n",
    "j = np.array(labels[\"strain\"][30:300])\n",
    "plt.plot( j,l[30:300], 'r*', label='Predicted Stress')\n",
    "k = np.array(labels[\"stress\"][30:300])\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.plot(j,k,\"g\",label = \"Actual Stress\")\n",
    "plt.legend(prop={\"size\":12})\n",
    "plt.title('Actual and predicted value of Stress',fontsize = 20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(hist.history)\n",
    "train_loss = hist.history['loss'][1:]\n",
    "val_loss   = hist.history['val_loss'][1:]\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "epochs = range(len(val_loss))\n",
    "plt.plot(epochs, train_loss, 'r', label='Training loss')\n",
    "plt.xlabel(\"No. of Epochs\",fontsize = 14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"Fraction\",fontsize = 14)\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss',fontsize = 20)\n",
    "plt.legend(prop={\"size\":12})\n",
    "\n",
    "plt.figure(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_24_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
